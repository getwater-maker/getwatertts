import os
import platform

# ImageMagick ì„¤ì • (í”Œë«í¼ë³„ ìë™ ê°ì§€)
if platform.system() == 'Windows':
    imagemagick_paths = [
        r'C:\Program Files\ImageMagick-7.1.2-Q16-HDRI\magick.exe',
        r'C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe',
        r'C:\Program Files\ImageMagick-7.1.0-Q16-HDRI\magick.exe',
        r'C:\Program Files\ImageMagick\magick.exe',
        r'C:\Program Files (x86)\ImageMagick\magick.exe',
    ]
    for path in imagemagick_paths:
        if os.path.exists(path):
            os.environ['IMAGEMAGICK_BINARY'] = path
            break
else:
    os.environ['IMAGEMAGICK_BINARY'] = '/usr/bin/convert'

import streamlit as st
import sys
import datetime
import numpy as np
import re
import tempfile

# ìƒìœ„ í´ë”ì˜ py ëª¨ë“ˆ ì‚¬ìš©ì„ ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'py'))

from helper import load_text_to_speech, load_voice_style, chunk_text  # type: ignore
import soundfile as sf
from docx import Document

# ì „ì—­ ë³€ìˆ˜
ASSETS_DIR = os.path.join(os.path.dirname(__file__), '..', 'assets')
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'outputs')
TEMP_DIR = os.path.join(os.path.dirname(__file__), 'temp')

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)


@st.cache_resource
def load_tts_model(use_gpu=False):
    """TTS ëª¨ë¸ ë¡œë“œ (ìºì‹œ)"""
    onnx_dir = os.path.join(ASSETS_DIR, 'onnx')
    model = load_text_to_speech(onnx_dir, use_gpu=use_gpu)
    return model


@st.cache_resource
def load_whisper_model():
    """Whisper ëª¨ë¸ ë¡œë“œ (ìºì‹œ)"""
    import whisper  # type: ignore
    return whisper.load_model("base")


def get_voice_list():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡"""
    voice_dir = os.path.join(ASSETS_DIR, 'voice_styles')
    voices = []
    if os.path.exists(voice_dir):
        for f in sorted(os.listdir(voice_dir)):
            if f.endswith('.json'):
                name = f.replace('.json', '')
                label = f"ì—¬ì„± {name[1]}" if name.startswith('F') else f"ë‚¨ì„± {name[1]}"
                voices.append(f"{label} ({name})")
    return voices


def get_voice_file(voice_label):
    """ìŒì„± ë¼ë²¨ì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ"""
    match = re.search(r'\(([^)]+)\)', voice_label)
    return f"{match.group(1)}.json" if match else "F1.json"


def read_text_file(uploaded_file):
    """TXT ë˜ëŠ” DOCX íŒŒì¼ ì½ê¸°"""
    if uploaded_file is None:
        return ""

    ext = os.path.splitext(uploaded_file.name)[1].lower()

    try:
        if ext == '.txt':
            return uploaded_file.read().decode('utf-8')
        elif ext == '.docx':
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ì½ê¸°
            temp_path = os.path.join(TEMP_DIR, uploaded_file.name)
            with open(temp_path, 'wb') as f:
                f.write(uploaded_file.read())
            doc = Document(temp_path)
            text = '\n'.join([para.text for para in doc.paragraphs if para.text.strip()])
            os.remove(temp_path)
            return text
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}"
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"


def get_max_length(lang):
    """ì–¸ì–´ë³„ ìµœëŒ€ ì²­í¬ ê¸¸ì´"""
    return 120 if lang == "ko" else 300


def analyze_audio_with_whisper(audio_path, language='ko'):
    """Whisperë¡œ ì˜¤ë””ì˜¤ ë¶„ì„"""
    model = load_whisper_model()
    lang_map = {'ko': 'ko', 'en': 'en', 'es': 'es', 'pt': 'pt', 'fr': 'fr'}
    whisper_lang = lang_map.get(language, 'ko')
    result = model.transcribe(audio_path, language=whisper_lang, word_timestamps=True, verbose=False)
    return result


def match_subtitles_to_audio(whisper_result, subtitle_lines, audio_duration):
    """ìë§‰ íƒ€ì„ì½”ë“œ ìƒì„±"""
    subtitle_timings = []
    segments = whisper_result.get('segments', [])

    if not subtitle_lines:
        return subtitle_timings

    total_lines = len(subtitle_lines)

    if segments:
        speech_start = segments[0]['start']
        speech_end = segments[-1]['end']
        speech_duration = speech_end - speech_start

        line_lengths = [len(line) for line in subtitle_lines]
        total_chars = sum(line_lengths)

        current_time = speech_start
        for i, line in enumerate(subtitle_lines):
            char_ratio = line_lengths[i] / total_chars if total_chars > 0 else 1 / total_lines
            line_duration = max(0.5, speech_duration * char_ratio)

            start_time = current_time
            end_time = min(current_time + line_duration, audio_duration)

            subtitle_timings.append({'text': line, 'start': start_time, 'end': end_time})
            current_time = end_time
    else:
        time_per_line = audio_duration / total_lines
        for i, line in enumerate(subtitle_lines):
            subtitle_timings.append({
                'text': line,
                'start': i * time_per_line,
                'end': (i + 1) * time_per_line
            })

    if subtitle_timings:
        subtitle_timings[-1]['end'] = audio_duration

    return subtitle_timings


def synthesize_speech(text, voice_label, language, speed, total_step, progress_callback=None):
    """ìŒì„± í•©ì„±"""
    if not text or not text.strip():
        return None, "í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        if progress_callback:
            progress_callback(0.1, "TTS ëª¨ë¸ ë¡œë“œ ì¤‘...")

        tts = load_tts_model()
        voice_file = get_voice_file(voice_label)
        voice_path = os.path.join(ASSETS_DIR, 'voice_styles', voice_file)
        style = load_voice_style([voice_path], verbose=False)

        max_len = get_max_length(language)
        chunks = chunk_text(text, max_len=max_len)
        total_chunks = len(chunks) if chunks else 1

        all_audio = []
        total_duration = 0.0

        for i, chunk in enumerate(chunks):
            if not chunk.strip():
                continue

            if progress_callback:
                progress_callback(0.2 + (i / total_chunks) * 0.6, f"ìŒì„± ìƒì„± ì¤‘ [{i+1}/{total_chunks}]")

            wav, duration = tts(chunk, language, style, int(total_step), float(speed))
            w = wav[0, :int(tts.sample_rate * duration[0].item())]
            all_audio.append(w)
            total_duration += duration[0].item()

            if i < total_chunks - 1:
                silence = np.zeros(int(0.3 * tts.sample_rate), dtype=np.float32)
                all_audio.append(silence)
                total_duration += 0.3

        if progress_callback:
            progress_callback(0.9, "íŒŒì¼ ì €ì¥ ì¤‘...")

        combined = np.concatenate(all_audio) if len(all_audio) > 1 else (all_audio[0] if all_audio else np.array([], dtype=np.float32))

        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"tts_{timestamp}.wav"
        filepath = os.path.join(OUTPUT_DIR, filename)
        sf.write(filepath, combined, tts.sample_rate)

        return filepath, f"ìŒì„± ìƒì„± ì™„ë£Œ! ê¸¸ì´: {total_duration:.1f}ì´ˆ"

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def create_video(tts_text, subtitle_text, voice_label, language, speed, total_step,
                 background_path, resolution, font_size, subtitle_position,
                 use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding,
                 progress_callback=None):
    """ì˜ìƒ ìƒì„±"""
    if not tts_text or not tts_text.strip():
        return None, "TTS í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    if not subtitle_text or not subtitle_text.strip():
        subtitle_text = tts_text

    try:
        from moviepy.editor import (
            ImageClip, VideoFileClip, AudioFileClip,
            CompositeVideoClip, TextClip, ColorClip
        )

        if progress_callback:
            progress_callback(0.05, "ì¤€ë¹„ ì¤‘...")

        video_width, video_height = map(int, resolution.split('x'))
        voice_file = get_voice_file(voice_label)

        # ë°°ê²½ íŒŒì¼ íƒ€ì…
        background_type = None
        if background_path:
            ext = os.path.splitext(background_path)[1].lower()
            background_type = 'video' if ext in ['.mp4', '.avi', '.mov', '.mkv', '.webm'] else 'image'

        # ìŒì„± ìƒì„±
        if progress_callback:
            progress_callback(0.1, "TTS ëª¨ë¸ ë¡œë“œ ì¤‘...")

        tts = load_tts_model()
        voice_path = os.path.join(ASSETS_DIR, 'voice_styles', voice_file)
        style = load_voice_style([voice_path], verbose=False)

        max_len = get_max_length(language)
        chunks = chunk_text(tts_text, max_len=max_len) or [tts_text]
        total_chunks = len(chunks)

        all_audio = []
        audio_duration = 0.0

        for i, chunk in enumerate(chunks):
            if not chunk.strip():
                continue

            if progress_callback:
                progress_callback(0.15 + (i / total_chunks) * 0.25, f"ìŒì„± [{i+1}/{total_chunks}]")

            wav, duration = tts(chunk, language, style, int(total_step), float(speed))
            w = wav[0, :int(tts.sample_rate * duration[0].item())]
            all_audio.append(w)
            audio_duration += duration[0].item()

            if i < total_chunks - 1:
                silence = np.zeros(int(0.3 * tts.sample_rate), dtype=np.float32)
                all_audio.append(silence)
                audio_duration += 0.3

        combined_audio = np.concatenate(all_audio) if len(all_audio) > 1 else (all_audio[0] if all_audio else np.array([], dtype=np.float32))

        if progress_callback:
            progress_callback(0.4, "ì˜¤ë””ì˜¤ ì €ì¥ ì¤‘...")

        temp_audio_path = os.path.join(TEMP_DIR, "temp_audio.wav")
        sf.write(temp_audio_path, combined_audio, tts.sample_rate)

        # Whisper ë¶„ì„
        subtitle_lines = [line.strip() for line in subtitle_text.split('\n') if line.strip()]

        if subtitle_lines:
            if progress_callback:
                progress_callback(0.45, "Whisper ë¶„ì„ ì¤‘...")
            try:
                whisper_result = analyze_audio_with_whisper(temp_audio_path, language)
                subtitle_timings = match_subtitles_to_audio(whisper_result, subtitle_lines, audio_duration)
            except Exception as e:
                print(f"Whisper ë¶„ì„ ì‹¤íŒ¨: {e}")
                time_per_line = audio_duration / len(subtitle_lines)
                subtitle_timings = [
                    {'text': line, 'start': i * time_per_line, 'end': (i + 1) * time_per_line}
                    for i, line in enumerate(subtitle_lines)
                ]
        else:
            subtitle_timings = []

        # ë°°ê²½ í´ë¦½
        if progress_callback:
            progress_callback(0.55, "ë°°ê²½ ì¤€ë¹„ ì¤‘...")

        if background_path and background_type == 'video':
            bg_clip = VideoFileClip(background_path)
            if bg_clip.duration < audio_duration:
                bg_clip = bg_clip.loop(duration=audio_duration)
            else:
                bg_clip = bg_clip.subclip(0, audio_duration)
            bg_clip = bg_clip.resize((video_width, video_height))
        elif background_path and background_type == 'image':
            bg_clip = ImageClip(background_path).set_duration(audio_duration)
            bg_clip = bg_clip.resize((video_width, video_height))
        else:
            bg_clip = ColorClip(size=(video_width, video_height), color=(26, 26, 46)).set_duration(audio_duration)

        # ìë§‰ ìœ„ì¹˜
        def get_subtitle_pos(pos, width, height, fsize):
            margin = 50
            positions = {
                'ìƒë‹¨-ì¤‘ì•™': ('center', margin),
                'ì¤‘ì•™': ('center', 'center'),
                'í•˜ë‹¨-ì¤‘ì•™': ('center', height - margin - fsize),
            }
            return positions.get(pos, ('center', height - margin - fsize))

        txt_position = get_subtitle_pos(subtitle_position, video_width, video_height, font_size)

        # ìë§‰ í´ë¦½ ìƒì„±
        if progress_callback:
            progress_callback(0.6, "ìë§‰ ìƒì„± ì¤‘...")

        subtitle_clips = []

        # í°íŠ¸ ì°¾ê¸°
        font_candidates = [
            '/usr/share/fonts/truetype/noto/NotoSansKR-Bold.ttf',
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc',
            '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',
            'C:/Windows/Fonts/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/malgunbd.ttf',
            'C:/Windows/Fonts/malgun.ttf',
        ]

        selected_font = None
        for font_path in font_candidates:
            if os.path.exists(font_path):
                selected_font = font_path
                break

        for i, timing in enumerate(subtitle_timings):
            line = timing['text']
            start_time = timing['start']
            end_time = timing['end']

            if not line:
                continue

            try:
                txt_clip = TextClip(
                    line,
                    fontsize=font_size,
                    color='white',
                    font=selected_font,
                    stroke_color='black',
                    stroke_width=2,
                    method='caption',
                    size=(video_width - 100, None)
                )

                # ìë§‰ ë°°ê²½ ë°•ìŠ¤
                if use_subtitle_bg:
                    txt_w, txt_h = txt_clip.size
                    bg_w = video_width + 10
                    bg_h = txt_h + int(subtitle_bg_padding * 2)

                    bg_box = ColorClip(size=(bg_w, bg_h), color=(0, 0, 0)).set_opacity(subtitle_bg_opacity)
                    bg_box = bg_box.set_duration(end_time - start_time)

                    bg_x = -5
                    if txt_position[1] == 'center':
                        bg_y = (video_height - bg_h) // 2
                    else:
                        txt_y = txt_position[1] if isinstance(txt_position[1], int) else 0
                        bg_y = txt_y - int(subtitle_bg_padding)

                    bg_box = bg_box.set_position((bg_x, bg_y))
                    bg_box = bg_box.set_start(start_time).set_end(end_time)
                    subtitle_clips.append(bg_box)

                txt_clip = txt_clip.set_position(txt_position)
                txt_clip = txt_clip.set_start(start_time).set_end(end_time)
                subtitle_clips.append(txt_clip)
            except Exception as e:
                print(f"ìë§‰ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")

        if progress_callback:
            progress_callback(0.75, "ì˜ìƒ í•©ì„± ì¤‘...")

        final_clip = CompositeVideoClip([bg_clip] + subtitle_clips)
        audio_clip = AudioFileClip(temp_audio_path)
        final_clip = final_clip.set_audio(audio_clip)

        if progress_callback:
            progress_callback(0.8, "ì˜ìƒ ì¸ì½”ë”© ì¤‘...")

        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"video_{timestamp}.mp4"
        filepath = os.path.join(OUTPUT_DIR, filename)

        final_clip.write_videofile(filepath, fps=30, codec='libx264', audio_codec='aac', verbose=False, logger=None)

        # ì •ë¦¬
        final_clip.close()
        audio_clip.close()
        if background_path and background_type == 'video':
            bg_clip.close()

        if os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)

        return filepath, f"ì˜ìƒ ìƒì„± ì™„ë£Œ! ê¸¸ì´: {audio_duration:.1f}ì´ˆ"

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def generate_preview(subtitle_text, background_path, resolution, font_size, subtitle_position,
                     use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding):
    """ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ìƒì„±"""
    try:
        from PIL import Image, ImageDraw, ImageFont

        font_size = int(font_size) if font_size and font_size >= 30 else 70
        subtitle_bg_opacity = float(subtitle_bg_opacity) if subtitle_bg_opacity else 0.6
        subtitle_bg_padding = int(subtitle_bg_padding) if subtitle_bg_padding else 20
        resolution = resolution if resolution else "1920x1080"

        video_width, video_height = map(int, resolution.split('x'))

        # ë°°ê²½
        if background_path:
            ext = os.path.splitext(background_path)[1].lower()
            if ext in ['.mp4', '.avi', '.mov', '.mkv', '.webm']:
                from moviepy.editor import VideoFileClip
                clip = VideoFileClip(background_path)
                frame = clip.get_frame(0)
                clip.close()
                bg_img = Image.fromarray(frame)
                bg_img = bg_img.resize((video_width, video_height), Image.LANCZOS)
            else:
                bg_img = Image.open(background_path)
                bg_img = bg_img.resize((video_width, video_height), Image.LANCZOS)
                bg_img = bg_img.convert('RGBA')
        else:
            bg_img = Image.new('RGBA', (video_width, video_height), (26, 26, 46, 255))

        # ìë§‰ í…ìŠ¤íŠ¸
        if not subtitle_text or not subtitle_text.strip():
            subtitle_text = "ìë§‰ ë¯¸ë¦¬ë³´ê¸°"

        first_line = subtitle_text.strip().split('\n')[0]

        # í°íŠ¸
        font_candidates = [
            '/usr/share/fonts/truetype/noto/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/malgunbd.ttf',
            'C:/Windows/Fonts/malgun.ttf',
        ]

        selected_font = None
        for font_path in font_candidates:
            if os.path.exists(font_path):
                selected_font = font_path
                break

        try:
            font = ImageFont.truetype(selected_font, font_size) if selected_font else ImageFont.load_default()
        except Exception:
            font = ImageFont.load_default()

        draw = ImageDraw.Draw(bg_img)
        bbox = draw.textbbox((0, 0), first_line, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]

        # ìœ„ì¹˜
        margin = 50
        positions = {
            'ìƒë‹¨-ì¤‘ì•™': ((video_width - text_width) // 2, margin),
            'ì¤‘ì•™': ((video_width - text_width) // 2, (video_height - text_height) // 2),
            'í•˜ë‹¨-ì¤‘ì•™': ((video_width - text_width) // 2, video_height - text_height - margin),
        }
        text_x, text_y = positions.get(subtitle_position, positions['í•˜ë‹¨-ì¤‘ì•™'])

        # ë°°ê²½ ë°•ìŠ¤
        if use_subtitle_bg:
            padding = int(subtitle_bg_padding)
            bg_h = text_height + padding * 2
            bg_x1 = -5
            bg_x2 = video_width + 5
            bg_y1 = text_y - padding
            bg_y2 = bg_y1 + bg_h

            overlay = Image.new('RGBA', bg_img.size, (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            alpha = int(255 * subtitle_bg_opacity)
            overlay_draw.rectangle([bg_x1, bg_y1, bg_x2, bg_y2], fill=(0, 0, 0, alpha))
            bg_img = Image.alpha_composite(bg_img.convert('RGBA'), overlay)

        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw = ImageDraw.Draw(bg_img)
        outline_width = 2
        for dx in range(-outline_width, outline_width + 1):
            for dy in range(-outline_width, outline_width + 1):
                if dx != 0 or dy != 0:
                    draw.text((text_x + dx, text_y + dy), first_line, font=font, fill=(0, 0, 0, 255))
        draw.text((text_x, text_y), first_line, font=font, fill=(255, 255, 255, 255))

        return bg_img.convert('RGB')

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None


# ========== Streamlit UI ==========

st.set_page_config(page_title="Supertonic TTS", page_icon="ğŸ™ï¸", layout="wide")

st.title("ğŸ™ï¸ Supertonic TTS")

# ì‚¬ì´ë“œë°”: ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    voices = get_voice_list()
    if not voices:
        voices = ["ìŒì„± íŒŒì¼ ì—†ìŒ"]

    voice = st.selectbox("ìŒì„±", voices)
    language = st.selectbox("ì–¸ì–´", ["í•œêµ­ì–´", "English", "EspaÃ±ol", "PortuguÃªs", "FranÃ§ais"])
    speed = st.slider("ì†ë„", 0.5, 2.0, 1.0, 0.1)
    quality = st.slider("í’ˆì§ˆ", 1, 10, 5, 1)

    st.divider()
    st.header("ğŸ¬ ì˜ìƒ ì„¤ì •")

    resolution = st.selectbox("í•´ìƒë„", ["1920x1080", "1280x720", "3840x2160", "1080x1920", "720x1280"])
    font_size = st.slider("í°íŠ¸ í¬ê¸°", 30, 120, 70, 5)
    subtitle_position = st.selectbox("ìë§‰ ìœ„ì¹˜", ["í•˜ë‹¨-ì¤‘ì•™", "ìƒë‹¨-ì¤‘ì•™", "ì¤‘ì•™"])

    use_subtitle_bg = st.checkbox("ìë§‰ ë°°ê²½", value=True)
    if use_subtitle_bg:
        subtitle_bg_opacity = st.slider("ë°°ê²½ íˆ¬ëª…ë„", 0.1, 1.0, 0.6, 0.1)
        subtitle_bg_padding = st.slider("ë°°ê²½ ì—¬ë°±", 5, 50, 20, 5)
    else:
        subtitle_bg_opacity = 0.6
        subtitle_bg_padding = 20

# ë©”ì¸ ì˜ì—­
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“ í…ìŠ¤íŠ¸ ì…ë ¥")

    # íŒŒì¼ ì—…ë¡œë“œ
    text_file = st.file_uploader("í…ìŠ¤íŠ¸/DOCX íŒŒì¼", type=['txt', 'docx'], key="text_file")

    if text_file:
        loaded_text = read_text_file(text_file)
        tts_text = st.text_area("í…ìŠ¤íŠ¸ (ìŒì„± ë³€í™˜ìš©)", value=loaded_text, height=200)
    else:
        tts_text = st.text_area("í…ìŠ¤íŠ¸ (ìŒì„± ë³€í™˜ìš©)", placeholder="ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", height=200)

    # ìë§‰ íŒŒì¼ ì—…ë¡œë“œ
    subtitle_file = st.file_uploader("ìë§‰ íŒŒì¼ (ì„ íƒ)", type=['txt', 'docx'], key="subtitle_file")

    if subtitle_file:
        loaded_subtitle = read_text_file(subtitle_file)
        subtitle_text = st.text_area("ìë§‰ (ë¹„ì›Œë‘ë©´ ìœ„ í…ìŠ¤íŠ¸ ì‚¬ìš©)", value=loaded_subtitle, height=150)
    else:
        subtitle_text = st.text_area("ìë§‰ (ë¹„ì›Œë‘ë©´ ìœ„ í…ìŠ¤íŠ¸ ì‚¬ìš©)", placeholder="í™”ë©´ì— í‘œì‹œë  ìë§‰...", height=150)

with col2:
    st.subheader("ğŸ–¼ï¸ ë°°ê²½")

    background_file = st.file_uploader("ë°°ê²½ ì´ë¯¸ì§€/ì˜ìƒ (ì²¨ë¶€í•˜ë©´ ì˜ìƒ ìƒì„±)", type=['jpg', 'jpeg', 'png', 'gif', 'mp4', 'avi', 'mov', 'mkv', 'webm'])

    # ë°°ê²½ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
    if background_file:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_bg_path = os.path.join(TEMP_DIR, f"temp_bg_{background_file.name}")
        with open(temp_bg_path, 'wb') as f:
            f.write(background_file.read())

        st.subheader("ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
        preview_text = subtitle_text if subtitle_text.strip() else tts_text
        preview_img = generate_preview(
            preview_text, temp_bg_path, resolution, font_size, subtitle_position,
            use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding
        )
        if preview_img:
            st.image(preview_img, use_container_width=True)
    else:
        temp_bg_path = None
        st.info("ğŸ’¡ ë°°ê²½ íŒŒì¼ì„ ì²¨ë¶€í•˜ë©´ ì˜ìƒì´ ìƒì„±ë©ë‹ˆë‹¤.\në°°ê²½ ì—†ì´ ìƒì„±í•˜ë©´ ìŒì„±ë§Œ ìƒì„±ë©ë‹ˆë‹¤.")

st.divider()

# ìƒì„± ë²„íŠ¼
col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
with col_btn2:
    if background_file:
        generate_button = st.button("ğŸ¬ ì˜ìƒ ìƒì„±", type="primary", use_container_width=True)
    else:
        generate_button = st.button("ğŸ™ï¸ ìŒì„± ìƒì„±", type="primary", use_container_width=True)

# ê²°ê³¼ ì˜ì—­
if generate_button:
    if not tts_text or not tts_text.strip():
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        lang_map = {"í•œêµ­ì–´": "ko", "English": "en", "EspaÃ±ol": "es", "PortuguÃªs": "pt", "FranÃ§ais": "fr"}
        lang_code = lang_map.get(language, "ko")

        progress_bar = st.progress(0)
        status_text = st.empty()

        def update_progress(value, text):
            progress_bar.progress(value)
            status_text.text(text)

        if background_file and temp_bg_path:
            # ì˜ìƒ ìƒì„±
            filepath, status = create_video(
                tts_text, subtitle_text, voice, lang_code, speed, quality,
                temp_bg_path, resolution, font_size, subtitle_position,
                use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding,
                update_progress
            )

            progress_bar.progress(1.0)

            if filepath:
                st.success(f"âœ… {status}")
                st.video(filepath)

                with open(filepath, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                        data=f,
                        file_name=os.path.basename(filepath),
                        mime="video/mp4"
                    )
            else:
                st.error(f"âŒ {status}")
        else:
            # ìŒì„±ë§Œ ìƒì„±
            filepath, status = synthesize_speech(
                tts_text, voice, lang_code, speed, quality,
                update_progress
            )

            progress_bar.progress(1.0)

            if filepath:
                st.success(f"âœ… {status}")
                st.audio(filepath)

                with open(filepath, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ìŒì„± ë‹¤ìš´ë¡œë“œ",
                        data=f,
                        file_name=os.path.basename(filepath),
                        mime="audio/wav"
                    )
            else:
                st.error(f"âŒ {status}")

# Footer
st.divider()
st.caption("Supertonic TTS - Streamlit ë²„ì „")
